{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 01 Why scalable computing matters**\n",
    "\n",
    "> jgxpjesb【】sharklasers.com\n",
    "\n",
    "**This chapter covers**\n",
    "- Presenting what makes Dask a standout framework for scalable computing\n",
    "- Demonstrating how to read and interpret directed acyclic graphs (DAGs) using a pasta recipe as a tangible example\n",
    "- Discussing why DAGs are useful for distributed workloads and how Dask’s task scheduler uses DAGs to compose, control, and monitor computations\n",
    "- Introducing the companion dataset\n",
    "\n",
    "This book was primarily written with beginner to intermediate data scientists, data engineers, and analysts in mind, specifically those who have not yet mastered working with data sets that push the limits of a single machine. We will broadly cover all areas of a data science project from data preparation to analysis to model building with applications in Dask and take a deep dive into fundamentals of distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Why Dask?\n",
    "\n",
    "Python and its Open Data Science Stack has become one of the most popular platforms both for learning data science and for everyday practitioners.\n",
    "\n",
    "<img align=\"center\" src=\"images/1.1t.png\"/>\n",
    "\n",
    "Dask was launched in late 2014 by Matthew Rocklin with aims to bring native scalability to the Python Open Data Science Stack and overcome its single-machine restrictions. Dask consists of several different components and APIs, which can be categorized into three layers: the scheduler, low-level APIs, and high-level APIs. \n",
    "\n",
    "Figure 1.1 The components and layers than make up Dask\n",
    "\n",
    "<img align=\"center\" src=\"images/1.1.png\"/>\n",
    "\n",
    "These computations are represented in code as either Dask Delayed objects or Dask Futures objects (the key difference is the former are evaluated **lazily** —meaning they are evaluated just in time when the values are needed, while the latter are evaluated **eagerly** —meaning they are evaluated in real time regardless if the value is needed immediately or not). Dask’s high-level APIs offer a layer of abstraction over Delayed and Futures objects. Operations on these high-level objects result in many parallel low-level operations managed by the task schedulers, which provides a seamless experience for the user. Because of this design, Dask brings four key advantages to the table:\n",
    "- Dask is fully implemented in Python and natively scales NumPy, Pandas, and scikit-learn.\n",
    "- Dask can be used effectively to work with both medium datasets on a single machine and large datasets on a cluster.\n",
    "- Dask can be used as a general framework for parallelizing most Python objects.\n",
    "- Dask has a very low configuration and maintenance overhead.\n",
    "\n",
    "Dask does a lot of the heavy lifting for common use cases, but throughout the book we’ll examine some best practices and pitfalls that will enable you to use Dask to its fullest extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Cooking with DAGs\n",
    "\n",
    "Dask's task schedulers use the concept of directed acyclic graphs (or DAGs for short) to compose, control, and express computations. DAGs come from a larger body of mathematics known as **_graph theory_**. But rather than continuing to talk about graphs in the abstract, let’s have a look at an example of using a DAG to model a real process.\n",
    "\n",
    "First, let’s take a quick overview of the recipe:\n",
    "\n",
    "<img align=\"center\" src=\"images/1.2.png\"/>\n",
    "\n",
    "A graph displaying nodes with dependencies:\n",
    "\n",
    "<img align=\"center\" src=\"images/1.3.png\"/>\n",
    "\n",
    "Once a node is complete, it is never repeated or revisited. This is what makes the graph an acyclic graph. If the graph contained a feedback loop or some kind of continuous process, it would instead be a **_cyclic graph_**. \n",
    "\n",
    "An example of a cyclic graph demonstrating an infinite feedback loop:\n",
    "\n",
    "<img align=\"center\" src=\"images/1.4.png\"/>\n",
    "\n",
    "From a programming perspective, this might sound like directed acyclic graphs would not allow looping operations. But this is not necessarily the case: a directed acyclic graph can be constructed from deterministic loops (such as for loops) by copying the nodes to be repeated and connecting them sequentially. \n",
    "\n",
    "The graph represented in figure 1.3 redrawn without transitive reduction:\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"images/1.5.png\"/>\n",
    "\n",
    "Figure 1.6 represents the full directed acyclic graph for the complete recipe. \n",
    "\n",
    "<img align=\"center\" src=\"images/1.6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Scaling out, concurrency, and recovery"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
